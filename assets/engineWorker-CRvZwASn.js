(function(){"use strict";const A={p95Multiplier:2,queueThreshold:.7};function G(i){const S=Math.max(i.serviceTimeMs,1e-6),u=Math.max(0,Math.min(i.cacheHitRate??0,1)),g=Math.max(0,i.cacheHitMs??0);return(1-u)*S+u*g}function ne(i){return i.protocol==="Kafka",0}function oe(i,S,u){return i<=u.queueThreshold?0:Math.pow(i,3)*S}function ae(i,S){const u=Math.max(0,Math.min(1,S??0)),g=Math.floor(i*(1-u*u));return Math.max(1,g)}function ce(i){return i.partitions*i.perPartitionThroughput}function re(i,S){const u=S.writeAmplification??4;let g=0,j=0,O=0;for(const $ of i){const N=$.rps;switch($.opType){case"write":j+=N;break;case"read":g+=N;break;default:O+=N;break}}const E=g+j*u+O;return{reads:g,writes:j,other:O,costUnits:E}}function le(i,S=A){const u={},g={},j=[],O=[],E={};for(const s of i.nodes)E[s.id]=0;for(const s of i.nodes)s.type==="ApiEndpoint"&&(E[s.id]+=s.dials.targetQps*(s.dials.burstFactor??1));const $=new Map,N=new Map;for(const s of i.nodes)$.set(s.id,[]),N.set(s.id,0);for(const s of i.edges)$.get(s.from).push(s.to),N.set(s.to,(N.get(s.to)||0)+1);const D=[];for(const[s,e]of N.entries())e===0&&D.push(s);const q=[];for(;D.length;){const s=D.shift();q.push(s);for(const e of $.get(s)||[]){const x=(N.get(e)||0)-1;N.set(e,x),x===0&&D.push(e)}}if(q.length<i.nodes.length)for(const s of i.nodes)q.includes(s.id)||q.push(s.id);const B=new Map,F=new Map;for(const s of i.edges)B.has(s.from)||B.set(s.from,[]),F.has(s.to)||F.set(s.to,[]),B.get(s.from).push(s),F.get(s.to).push(s);for(const s of q){const e=i.nodes.find(a=>a.id===s),x=E[s]||0;if(e.type==="Service"){const o=(F.get(e.id)??[]).map(t=>({e:t,rps:g[t.id]?.flowRps??0})).map(t=>t.rps),p=o.length;let c=x,M=[],h=new Array(p).fill(0),d;const r=e.dials.join,b=(t,l)=>t*(l==null?1:Math.max(0,Math.min(1,l)));if(!r||r.type==="none"||p===0)c=o.reduce((t,l)=>t+l,0),h=o.slice(),M=o.map((t,l)=>l),d="merge";else if(r.type==="all"){const t=p>0?Math.min(...o):0;c=b(t,r.efficiency),h=new Array(p).fill(c),M=o.map((l,m)=>m),d=`all: min=${t}`}else if(r.type==="kOfN"){const t=Math.max(1,Math.min(r.requiredStreams,Math.max(1,p))),l=o.map((f,P)=>({r:f,i:P})).sort((f,P)=>P.r-f.r),m=l.length>=t?l[t-1].r:0,I=o.reduce((f,P)=>f+P,0),L=Math.min(m,I/Math.max(1,t));c=b(L,r.efficiency),M=l.slice(0,t).map(f=>f.i),h=o.map((f,P)=>M.includes(P)?c:0),d=`kOfN k=${t}: min(kth=${m}, sum/k=${(I/Math.max(1,t)).toFixed(2)})`}else if(r.type==="window"){const t=Math.max(1,Math.min(r.requiredStreams,Math.max(1,p))),l=o.map((T,C)=>({r:T,i:C})).sort((T,C)=>C.r-T.r),m=l.length>=t?l[t-1].r:0,I=o.reduce((T,C)=>T+C,0),L=Math.min(m,I/Math.max(1,t)),f=Math.max(0,Math.min(1,r.matchRate)),P=L*f;c=b(P,r.efficiency),M=l.slice(0,t).map(T=>T.i),h=o.map((T,C)=>M.includes(C)?c:0),d=`window k=${t}: bound * match=${f}`}let R=c;const y=(F.get(e.id)??[]).filter(t=>t.protocol==="Kafka");let w=0;for(const t of y){const l=i.nodes.find(m=>m.id===t.from);l&&l.type==="QueueTopic"&&(w+=l.dials.partitions)}const v=y.length>0?Math.min(e.dials.concurrency,w):e.dials.concurrency,U=Math.max(0,Math.min(e.dials.parallelEfficiency??1,1)),fe=G(e.dials);let k=v*U*(1e3/Math.max(fe,1e-6));const me=e.penalties?.capacityMultiplier??1;k*=me,e.penalties?.fixedRpsCap!=null&&(k=Math.min(k,e.penalties.fixedRpsCap)),e.dials.maxInFlight!=null&&(k=Math.min(k,e.dials.maxInFlight));let te;if(y.length>0){let t=1/0;for(const l of y){const m=i.nodes.find(I=>I.id===l.from);if(m&&m.type==="QueueTopic"){const I=m.dials.partitions,L=m.dials.perPartitionThroughput,f=e.dials.concurrency,P=Math.min(I,f)*L;t=Math.min(t,P)}}te=t,k=Math.min(k,t)}const K=R/Math.max(k,1e-6),se=G(e.dials),ue=oe(K,se,S);let _=se+ue;_=_*(e.penalties?.latencyMultiplier??1)+(e.penalties?.latencyMsAdd??0);const he=_*A.p95Multiplier;let z=Math.min(R,k);z=Math.min(z,e.penalties?.fixedRpsCap??1/0),z=z*(e.penalties?.throughputMultiplier??1);const Y=Math.max(0,R-k),Me=i.edges.filter(t=>t.to===e.id&&t.protocol==="Kafka");let H=0;for(const t of Me){const l=i.nodes.find(m=>m.id===t.from);l&&l.type==="QueueTopic"&&(H=Math.max(H,l.dials.partitions))}let ie;if(H>0){const t=Math.max(0,Math.min(e.dials.parallelEfficiency??1,1)),l=H*t,m=e.dials.concurrency-l;ie=m>0?m:void 0}const V=[];K>=1?V.push(`Inbound ${R.toFixed(1)} RPS exceeds service capacity (${k.toFixed(1)}). Backlog growing by ${(R-k).toFixed(1)} RPS.`):K>=.85?V.push("High utilization (≥0.85)"):K>=.7&&V.push("Elevated utilization (≥0.70)"),Y>0&&O.push({id:e.id,reason:"Capacity exceeded"});let Q={type:"none",reason:"no constraint"};const ye=!!r&&r.type!=="none"&&p>0;k<=R+1e-6?Q={type:"service-compute",reason:`capacity ${k.toFixed(1)}/s`}:ye&&(r.type==="all"?Q={type:"join-all",reason:d??"join=all"}:r.type==="kOfN"?Q={type:"join-kofn",reason:d??"join=kOfN"}:r.type==="window"&&(Q={type:"window-correlation",reason:d??"join=window"})),u[e.id]={ingressRps:R,egressRps:z,utilization:K,modeledP50Ms:_,modeledP95Ms:he,backlogRps:Y>0?Y:void 0,wastedConcurrency:ie,warnings:V,limiter:Q,details:{service:{joinMode:e.dials.join?.type??"none",joinSummary:r?{requiredStreams:r.requiredStreams,efficiency:r.efficiency,matchRate:r.matchRate,activeStreamsCount:M.length,joinIngressRps:c,limiter:d}:void 0,workers:v,availablePartitions:y.length>0?w:void 0,consumerCap:te}}};{const t=F.get(s)??[],l=u[s],m=l.ingressRps>0?Math.min(1,l.egressRps/Math.max(l.ingressRps,1e-6)):1;for(let I=0;I<t.length;I++){const L=t[I],f=g[L.id];if(!f)continue;const P=h[I]??f.flowRps,C=Math.min(P,f.flowRps)*m,J=Math.max(0,f.flowRps-C);f.deliveredRps=C,f.blockedRps=(f.blockedRps??0)+J,J>0&&f.warnings.push(`Target constrained: blocked ${J.toFixed(2)}/s`)}}}else if(e.type==="QueueTopic"){const a=e;let n=ce(a.dials);n*=e.penalties?.capacityMultiplier??1,e.penalties?.fixedRpsCap!=null&&(n=Math.min(n,e.penalties.fixedRpsCap));const o=B.get(e.id)??[];let p=0;for(const w of o){const v=i.nodes.find(U=>U.id===w.to);if(v&&v.type==="Service"){const U=v.dials.concurrency;p+=Math.min(a.dials.partitions,U)*a.dials.perPartitionThroughput}}let c=Math.min(x,n,p||1/0);c=Math.min(c,e.penalties?.fixedRpsCap??1/0),c=c*(e.penalties?.throughputMultiplier??1);const M=Math.max(0,x-c);let h="none",d="no constraint";const r=[{t:"producer-partitions",v:x,reason:`producer total ${x.toFixed(1)}/s`},{t:"partitions",v:n,reason:`partitions cap ${n.toFixed(1)}/s`},{t:"consumer-parallelism",v:p||1/0,reason:`consumer cap ${isFinite(p)?p.toFixed(1):"∞"}/s`}],b=Math.min(...r.map(w=>w.v)),R=r.find(w=>w.v===b);h=R.t,d=R.reason;let y;x<n-1e-6&&x<(p||1/0)-1e-6&&R.t!=="producer-partitions"&&(y={type:"producer-partitions",reason:"producer limited ingress",inputRps:x}),u[e.id]={ingressRps:x,egressRps:c,utilization:x/Math.max(n,1e-6),modeledP50Ms:0,modeledP95Ms:0,consumerLagRps:M>0?M:void 0,warnings:[],limiter:{type:h,reason:d},upstreamConstraint:y,details:{topic:{partitions:a.dials.partitions,consumerCapTotal:p||0}}}}else if(e.type==="ApiEndpoint"){let a=x;e.penalties?.fixedRpsCap!=null&&(a=Math.min(a,e.penalties.fixedRpsCap)),a=a*(e.penalties?.throughputMultiplier??1);const o=(e.dials.p50Ms??0)*(e.penalties?.latencyMultiplier??1)+(e.penalties?.latencyMsAdd??0),p=e.dials.p95Ms!=null?e.dials.p95Ms:o*A.p95Multiplier;u[e.id]={ingressRps:x,egressRps:a,utilization:0,modeledP50Ms:o,modeledP95Ms:p,warnings:[],limiter:{type:"none",reason:"entry"}}}else if(e.type==="Datastore"){const a=F.get(e.id)??[],n=re(a.map(v=>({rps:g[v.id]?.flowRps??E[e.id],opType:v.opType})),e.dials);let o=e.dials.maxQps;const p=Math.max(1,e.dials.poolSize??Number.POSITIVE_INFINITY),c=Math.max(1,e.dials.maxConcurrent??Number.POSITIVE_INFINITY),M=isFinite(p)&&isFinite(c)?p*c:isFinite(p)?p:isFinite(c)?c:1/0;isFinite(M)&&(o=Math.min(o,M)),o*=e.penalties?.capacityMultiplier??1,e.penalties?.fixedRpsCap!=null&&(o=Math.min(o,e.penalties.fixedRpsCap));const h=n.costUnits/Math.max(o,1e-6);let d=e.dials.p95Ms/1.5;if(n.writes>0&&(e.dials.lockContentionFactor??0)>0){const v=n.writes/Math.max(n.costUnits,1e-6);d=d*(1+v*(e.dials.lockContentionFactor??0))}d=d*(e.penalties?.latencyMultiplier??1)+(e.penalties?.latencyMsAdd??0);const r=d*A.p95Multiplier,b=x,R=Math.min(1,o/Math.max(n.costUnits,1e-6));let y=b*R;y=Math.min(y,e.penalties?.fixedRpsCap??1/0),y=y*(e.penalties?.throughputMultiplier??1);const w=Math.max(0,n.costUnits-o);w>0&&O.push({id:e.id,reason:"Datastore capacity limit"}),u[e.id]={ingressRps:b,egressRps:y,utilization:h,modeledP50Ms:d,modeledP95Ms:r,backlogRps:w>0?w:void 0,warnings:[],limiter:R<1?{type:"datastore-capacity",reason:`capacity ${o.toFixed(1)} costUnits/s`}:{type:"none",reason:"under capacity"},details:{datastore:{reads:n.reads,writes:n.writes,costUnits:n.costUnits,capacity:o}}}}if(e.type!=="Service"){const a=F.get(s)??[],n=u[s],o=n.ingressRps>0?Math.min(1,n.egressRps/Math.max(n.ingressRps,1e-6)):1;for(const p of a){const c=g[p.id];if(!c)continue;const M=c.flowRps*o,h=Math.max(0,c.flowRps-M);c.deliveredRps=M,c.blockedRps=(c.blockedRps??0)+h,h>0&&c.warnings.push(`Target constrained: blocked ${h.toFixed(2)}/s`)}}const X=B.get(s)??[],Z=u[s],ee=i.nodes.find(a=>a.id===s),pe=ee?.type==="Service"&&ee.dials.fanOut==="duplicate",de=X.reduce((a,n)=>a+(n.weight??1),0)||1;for(const a of X){let n=pe?Z.egressRps:Z.egressRps*((a.weight??1)/de);const o=n;if(a.protocol==="Kafka"){const h=i.nodes.find(r=>r.id===a.to),d=i.nodes.find(r=>r.id===a.from);if(h&&h.type==="QueueTopic"){const r=ae(h.dials.partitions,a.keySkew),b=h.dials.perPartitionThroughput,R=r*b,y=d&&d.type==="Service"?d.dials.concurrency:1/0,w=Math.min(R,isFinite(y)?y*b:1/0);n=Math.min(n,w)}}E[a.to]=(E[a.to]||0)+n;const p=ne(a),c=[],M=n+1e-6<o?{type:"producer-partitions",reason:"producer cap on Kafka edge"}:void 0;g[a.id]={flowRps:n,modeledLatencyMs:p,deliveredRps:n,blockedRps:0,warnings:c,limiter:M}}}return{nodeStats:u,edgeStats:g,global:{warnings:j,bottlenecks:O}}}let W;self.onmessage=i=>{const{data:S}=i;S.type==="compute"&&(W&&clearTimeout(W),W=setTimeout(()=>{const g={type:"result",result:le(S.graph,A)};self.postMessage(g)},150))}})();
